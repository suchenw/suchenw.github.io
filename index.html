<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Suchen Wang | Senior Applied Scientist</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta
    name="description"
    content="Personal website of Suchen Wang, Senior Applied Scientist at Amazon AWS AI Solutions, specializing in computer vision, Just Walk Out (JWO), video understanding, and vision-language models."
  />

  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link
    href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
    rel="stylesheet"
  />

  <!-- Font Awesome -->
  <link
    rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css"
  />

  <!-- CSS -->
  <link rel="stylesheet" href="styles.css" />
</head>

<body id="top">

<!-- ================= HEADER ================= -->
<header class="site-header">
  <div class="container header-inner">
    <div class="logo">
      <a href="#top">Suchen <span>Wang</span>, Ph.D.</span></a>
    </div>

    <nav class="nav">
      <a href="#about">About</a>
      <a href="#experience">Experience</a>
      <a href="#research">Research</a>
      <a href="#service">Service</a>
      <a href="#contact">Contact</a>
    </nav>
  </div>
</header>

<!-- ================= HERO ================= -->
<section class="hero">
  <div class="container hero-inner">
    <div class="hero-text">
      <p class="hero-kicker">Senior Applied Scientist · Computer Vision</p>

      <h1>Hi, I’m <span>Suchen Wang.</span></h1>

      <p class="hero-summary">
        I’m a Senior Applied Scientist at Amazon AWS AI Solutions, working on
        <strong>Just Walk Out (JWO)</strong> autonomous retail technology.
        I design and deploy <strong>large-scale perception systems</strong>
        that power seamless, frictionless shopping experiences across hundreds
        of automated retail stores worldwide.
      </p>

      <p class="hero-summary">
        My current work focuses on
        <strong>vision-language models</strong> and improving
        <strong>video reasoning capabilities</strong> to better understand
        actions, interactions, and how humans engage with the physical world.
      </p>

      <div class="hero-actions">

        <!-- View my work -->
        <a href="#research" class="btn primary-btn">
          <i class="fa-solid fa-book-open"></i> View my work
        </a>

        <!-- YouTube demo button -->
        <a
        href="https://www.youtube.com/watch?v=qV5TSE6rxwY"
        target="_blank"
        rel="noreferrer"
        class="btn youtube-full-btn"
        >
        <i class="fa-brands fa-youtube"></i>
        Watch JWO Demo
        </a>

        <!-- Contact -->
        <a href="#contact" class="btn ghost-btn">
          <i class="fa-solid fa-envelope"></i> Contact me
        </a>
      </div>

      <div class="hero-meta hero-meta-top">
        <!-- Location -->
        <div class="meta-item">
            <i class="fa-solid fa-location-dot"></i>
            Seattle, WA, USA
        </div>

        <!-- Education -->
        <div class="meta-item">
            <i class="fa-solid fa-graduation-cap"></i>
            Ph.D., Nanyang Technological University, Singapore
        </div>

        <!-- Email -->
        <div class="meta-item">
            <i class="fa-solid fa-envelope"></i>
            <a href="mailto:suchenusa@gmail.com">suchenusa [at/@] gmail [.] com</a>
        </div>

        <!-- LinkedIn -->
        <div class="meta-item">
            <i class="fa-brands fa-linkedin"></i>
            <a href="https://www.linkedin.com/in/suchen-wang-b2624b165/"
            target="_blank">
            LinkedIn
            </a>
        </div>

        <!-- Google Scholar -->
        <div class="meta-item">
            <i class="fa-solid fa-graduation-cap"></i>
            <a href="https://scholar.google.com.sg/citations?user=eP__svIAAAAJ&hl=en"
            target="_blank">
            Google Scholar
            </a>
        </div>
        </div>
    </div>

    <div class="hero-photo">
      <img src="images/profile.png" alt="Portrait of Suchen Wang">
    </div>
  </div>
</section>

<!-- ================= ABOUT ================= -->
<section id="about" class="section">
  <div class="container">
    <h2>About</h2>

    <div class="card about-card">
      <p>
        I'm a Senior Applied Scientist at Amazon AWS, working on Just Walk Out (JWO) autonomous retail technology. I received my Ph.D. from Nanyang Technological University (NTU), Singapore in 2022, advised by
        <a href="https://cse.buffalo.edu/~jsyuan/" target="_blank">Prof. Junsong Yuan</a> and <a href="https://scholar.google.com/citations?user=9sQVUMoAAAAJ&hl=en" target="_blank">Prof. Yap-Peng Tan</a>.
        My research interests span action recognition, object detection, human–object interaction (HOI), large-scale video understanding, and visual reasoning.
      </p>

      <p>
        Just Walk Out (JWO) is Amazon’s checkout-free retail technology that uses machine learning and computer vision to create a checkout-free shopping experience. This system allows shoppers to enter a store, take the items
        they want, and simply walk out without having to use a traditional checkout. The total for their items is automatically charged to their payment method after they exit. 
        I'm working at the shopping team with mission of generating accurate receipts. As shoppers pick up items, overhead cameras and the shopping model running behind will add the picked products to their virtual cart.
        Our shopping model continuously recognizes shopping activities to maintain individual virtual cart for each shopper.
        Since joining Amazon, I'm contributing to JWO’s large-scale perception systems.
        We have built and developed visual reasoning models that power 300+ JWO stores across the United States, United Kingdom, Canada, Australia, and France, etc.
      </p>
    </div>
  </div>
</section>

<!-- ================= EXPERIENCE ================= -->
<section id="experience" class="section">
  <div class="container">
    <h2>Experience</h2>

    <div class="experience-grid">

      <!-- Senior Applied Scientist -->
      <article class="card experience-card">
        <div class="experience-header">
          <h3>Senior Applied Scientist</h3>
          <span class="company">Amazon AWS AI Solutions · JWO Research</span>
          <span class="timeplace">Seattle, WA · Dec 2022 – Present</span>
        </div>
        <ul>
          <li>Worked with an excellent small team to develop the first visual-reasoning multimodal LLMs for Just Walk Out receipt generation, including pretraining visual encoders, mid-training the reasoning language model, and post-training for real-world robustness.</li>
        </ul>
      </article>

      <!-- Applied Scientist II -->
      <article class="card experience-card">
        <div class="experience-header">
          <h3>Applied Scientist II</h3>
          <span class="company">Amazon AWS AI Solutions · JWO Research</span>
          <span class="timeplace">Seattle, WA · Nov 2022 – Nov 2024</span>
        </div>
        <ul>
          <li>Built perception components for new store formats, including 
            <a href="https://www.youtube.com/watch?v=3l92WikZEVs" target="_blank">Education Stores</a> 
            and 
            <a href="https://www.youtube.com/watch?v=5_vVnspgf8U" target="_blank">Arena self-serve bars</a>. </li>
        </ul>
      </article>

      <!-- NTU Research Assistant -->
      <article class="card experience-card">
        <div class="experience-header">
          <h3>Research Assistant</h3>
          <span class="company">Nanyang Technological University (NTU)</span>
          <span class="timeplace">Singapore · Sep 2016 – Oct 2022</span>
        </div>
        <ul>
          <li>Conducted research in HOI detection, multi-view vision, video understanding, and behavior modeling.</li>
          <li>Developed perception algorithms for smart classrooms, robotics, and video analytics.</li>
          <li>Published in CVPR, ICCV, IJCAI, TPAMI, TIP.</li>
        </ul>
      </article>

    </div>
  </div>
</section>

<!-- ================= RESEARCH + PUBLICATIONS ================= -->
<section id="research" class="section">
  <div class="container">
    <h2>Research & Publications</h2>

    <p class="section-subtitle">Research Interests</p>

    <div class="card pill-card">
      <ul class="pill-list">
        <li>Action recognition & temporal reasoning</li>
        <li>Human–object interaction (HOI)</li>
        <li>Object detection & segmentation</li>
        <li>Video reasoning & analytics</li>
        <li>Vision-language models</li>
        <li>Multi-camera perception</li>
      </ul>
    </div>

    <h3 style="margin-top: 2rem;">Selected Publications</h3>
    <p class="section-subtitle">
      Full list available on
      <a href="https://scholar.google.com.sg/citations?user=eP__svIAAAAJ&hl=en" target="_blank">
        Google Scholar
      </a>.
    </p>

    <div class="card pubs-card">
      <ol class="pub-list">

        <li><strong>Boundary Voting Network for Ambiguity-aware Timestamp-supervised Action Segmentation.</strong><br />
          Runzhong Zhang, Yueqi Duan, Yang Chen, Weipeng Hu, Chen Cai,
          <strong>Suchen Wang</strong>, Yap-Peng Tan.
          <em>IEEE TCSVT, 2025.</em>
        </li>

        <li><strong>Top-down Framework for Weakly-supervised Grounded Image Captioning.</strong><br />
          Chen Cai, <strong>Suchen Wang</strong>, Kim-Hui Yap, Yi Wang.
          <em>KBS, 2024.</em>
        </li>

        <li><strong>HOI-Aware Adaptive Network for Weakly Supervised Action Segmentation.</strong><br />
          Runzhong Zhang, <strong>Suchen Wang</strong>, Yueqi Duan, Yansong Tang, Yue Zhang, Yap-Peng Tan.
          <em>IJCAI, 2023.</em>
        </li>

        <li><strong>VLT: Vision-Language Transformer for Referring Segmentation.</strong><br />
          Henghui Ding, Chang Liu, <strong>Suchen Wang</strong>, Xudong Jiang.
          <em>IEEE TPAMI, 2022.</em>
        </li>

        <li><strong>Learning Transferable Human-Object Interaction Detector with Natural Language Supervision.</strong><br />
          <strong>Suchen Wang</strong>, Yueqi Duan, Henghui Ding, Yap-Peng Tan, Kim-Hui Yap, Junsong Yuan.
          <em>CVPR, 2022.</em>
        </li>

        <li><strong>Discovering Human Interactions with Large-Vocabulary Objects via Multi-Scale Detection.</strong><br />
          <strong>Suchen Wang</strong>, Kim-Hui Yap, Henghui Ding, Jiyan Wu, Junsong Yuan, Yap-Peng Tan.
          <em>ICCV, 2021.</em>
        </li>

        <li><strong>Vision-Language Transformer and Query Generation for Referring Segmentation.</strong><br />
          Henghui Ding, Chang Liu, <strong>Suchen Wang</strong>, Xudong Jiang.
          <em>ICCV, 2021.</em>
        </li>

        <li><strong>Discovering Human Interactions with Novel Objects via Zero-shot Learning.</strong><br />
          <strong>Suchen Wang</strong>, Kim-Hui Yap, Junsong Yuan, Yap-Peng Tan.
          <em>CVPR, 2020.</em>
        </li>

        <li><strong>Joint Representative Selection and Feature Learning: A Semi-Supervised Approach</strong><br />
          <strong>Suchen Wang</strong>, Jingjing Meng, Junsong Yuan, Yap-Peng Tan
          <em>CVPR, 2019.</em>
        </li>

        <li><strong>Video Summarization via Multi-View Representative Selection.</strong><br />
          Jingjing Meng, <strong>Suchen Wang</strong>, Hongxing Wang, Junsong Yuan, Yap-Peng Tan.
          <em>IEEE TIP, 2018.</em>
        </li>

      </ol>
    </div>
  </div>
</section>

<!-- ================= SERVICE ================= -->
<section id="service" class="section">
  <div class="container">
    <h2>Service</h2>

    <div class="card service-card">
      <ul>
        <li><strong>Outstanding Reviewer</strong>, CVPR 2025.</li>
        <li>Reviewer for top-tier conferences: CVPR, ICCV, ECCV, NeurIPS, ICASSP.</li>
        <li>Reviewer for journals: IEEE TPAMI, TIP, TMM, TCSVT.</li>
      </ul>
    </div>
  </div>
</section>

<!-- ================= CONTACT ================= -->
<section id="contact" class="section">
  <div class="container">
    <h2>Contact</h2>

    <div class="card contact-card">
      <p>You can reach me by email or connect with me on LinkedIn.</p>

      <div class="contact-grid">
        <div class="contact-item">
          <i class="fa-solid fa-envelope"></i>
          <a href="mailto:suchenusa@gmail.com">suchenusa [at/@] gmail [dot] com</a>
        </div>

        <div class="contact-item">
          <i class="fa-brands fa-linkedin"></i>
          <a href="https://www.linkedin.com/in/suchen-wang-b2624b165/" target="_blank">
            LinkedIn
          </a>
        </div>

        <div class="contact-item">
          <i class="fa-solid fa-graduation-cap"></i>
          <a
            href="https://scholar.google.com.sg/citations?user=eP__svIAAAAJ&hl=en"
            target="_blank">
            Google Scholar
          </a>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ================= FOOTER ================= -->
<footer class="site-footer">
  <div class="container footer-inner">
    <span>© <span id="year"></span> Suchen Wang</span>
    <span class="footer-note">Built with HTML & CSS</span>
  </div>
</footer>

<script>
  document.getElementById("year").textContent = new Date().getFullYear();
</script>

</body>
</html>